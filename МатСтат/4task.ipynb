{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70065845",
   "metadata": {},
   "source": [
    "## Шевцова Софья\n",
    "группа 20930\n",
    "\n",
    "15 вариант\n",
    "\n",
    "Iris versicolor, Iris virginica Длина лепестка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "91265c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setosa = [0], versicolor = [1], virginica = [2]\n",
      "Для 1.0 [0]\n",
      "Для 1.9 [0]\n",
      "Для 2.45 [1]\n",
      "Для 3.0 [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofya\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\internal\\slicing.py:135: UserWarning: Unable to find property getter for parameter Tensor scale_diag on tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[3], event_shape=[1], dtype=float64), falling back to Distribution.dtype <dtype: 'float64'>\n",
      "  warnings.warn('Unable to find property getter for parameter Tensor {} '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для 4.5 [1]\n",
      "Для 4.8 [1]\n",
      "Для 5.1 [2]\n",
      "Для 6.0 [2]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets, model_selection\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def get_prior(y): # априорное распределение вероятностей\n",
    "    num_classes = tf.reduce_max(y) + 1\n",
    "    probs = np.zeros((num_classes,))\n",
    "    for item in y:\n",
    "        probs[item] +=1\n",
    "    probs = probs/len(y)\n",
    "    return tfd.Categorical(probs = probs)\n",
    "\n",
    "\n",
    "def get_class_conditionals(x, y): # условное распределение\n",
    "    num_classes = tf.reduce_max(y).numpy() + 1\n",
    "    num_samples = x.shape[0]\n",
    "    num_features = x.shape[1]\n",
    "    loc = np.zeros((num_classes, num_features))\n",
    "    scale_diag = np.zeros((num_classes, num_features))\n",
    "    nos_in_class = np.zeros((num_classes,))\n",
    "    for i in range(num_samples):\n",
    "        nos_in_class[y[i]]+=1  \n",
    "    nos_in_class = np.expand_dims(nos_in_class, axis = 1)    \n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_features):\n",
    "            loc[y[i], j] += x[i,j]      \n",
    "    loc = loc/nos_in_class\n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_features):\n",
    "            scale_diag[y[i], j] += (x[i,j]-loc[y[i],j])**2   \n",
    "    scale_diag = np.sqrt(scale_diag/nos_in_class)\n",
    "    return tfd.MultivariateNormalDiag(loc = loc, scale_diag = scale_diag)\n",
    "\n",
    "\n",
    "def predict_class(prior, class_conditionals, x): # вычисляет вероятности классов, возвращает тот, у котрого оан больше\n",
    "    num_classes = tf.squeeze(class_conditionals.batch_shape)\n",
    "    probs = []\n",
    "    for i in range(num_classes):\n",
    "        probs.append(tf.cast(class_conditionals[i].prob(x),dtype = tf.float32)*tf.cast(prior.probs[i], dtype = tf.float32))\n",
    "    predictions = np.argmax(probs, axis = 0)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "iris = datasets.load_iris() # загружаем базу ирисов\n",
    "data = iris.data[:, 2:] # длины лепестков\n",
    "data = data[:, :1]\n",
    "targets = iris.target # названия ирисов\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(data, targets, test_size=0.2) # делим на 80% тренировки и 20% тест\n",
    "prior = get_prior(y_train)\n",
    "class_conditionals = get_class_conditionals(x_train, y_train)\n",
    "predictions = predict_class(prior, class_conditionals, x_test)\n",
    "accuracy = accuracy_score(y_test, predictions) # точность предсказаний\n",
    "print(\"Setosa = [0], versicolor = [1], virginica = [2]\")\n",
    "print(\"Для 1.0\", predict_class(prior, class_conditionals, [[1.0]] ))\n",
    "print(\"Для 1.9\",predict_class(prior, class_conditionals, [[1.9]] ))\n",
    "print(\"Для 2.45\",predict_class(prior, class_conditionals, [[2.45]] ))\n",
    "print(\"Для 3.0\",predict_class(prior, class_conditionals, [[3.0]] ))\n",
    "print(\"Для 4.5\",predict_class(prior, class_conditionals, [[4.5]] ))\n",
    "print(\"Для 4.8\",predict_class(prior, class_conditionals, [[4.8]] ))\n",
    "print(\"Для 5.1\",predict_class(prior, class_conditionals, [[5.1]] ))\n",
    "print(\"Для 6.0\",predict_class(prior, class_conditionals, [[6.0]] ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c546234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2. Оценить точность классификации при случайном разбиении выборки на обучающую (80%) и контрольную выборки (20%)\n",
      "Точность: 0.9000\n"
     ]
    }
   ],
   "source": [
    "# 4.2\n",
    "print('4.2. Оценить точность классификации при случайном разбиении выборки на обучающую (80%) и контрольную выборки (20%)')\n",
    "print(\"Точность: {:.4f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
